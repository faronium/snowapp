{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5cb1d9a-f917-4562-8ccc-7580377c5679",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # Snow Data\n",
    "#\n",
    "# Tool to import archived snow data and manipulate it using python pandas. Eventually\n",
    "# to plot with plotlinkedinly/dash app of some kind.\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dash import Dash, html, dcc, Input, Output, callback\n",
    "import plotly.graph_objects as go\n",
    "import dash_bootstrap_components as dbc\n",
    "from datetime import datetime\n",
    "import time\n",
    "from snowdata import get_wyear_extrema_oni, get_oni_startrange, load_munge_snow_data, count_coverage, get_median\n",
    "from documentation import how_to_md, analysis_desc_md, header_text_md, footer_text_md\n",
    "from snowmap import draw_station_map\n",
    "from snowplot import snow_lineplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cab3932b-ef4c-4591-9c9e-cc6fc35d4c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nAuthor: Faron Anslow\\nE-mail: faron.anslow@gmail.com\\n\\nThis code generates a Dash web browser application that plots single station water-year snow evolution with\\ncontrols to filter by station location and ENSO state. Default is to display the median and 1-sigma range\\nfor the entire record, the median and 1-sigma range for a selected ENSO condition and the current year's\\nsnowpack evolution.\\n\\nFuture iterations will include a map-view component that will display the station locations with symbology\\nthat illustrates the relationship between various snow statistics (such as timing of peak, amplitude of peak,\\ntiming of peak melt, amplitude of peak melt and timing of snow loss) and seasonal teleconnection/variability\\npatterns.\\n\\nSources for snow data and teleconnection index values.\\nSnow data URL: https://www.env.gov.bc.ca/wsd/data_searches/snow/asws/data/\\nONI data URL: https://www.cpc.ncep.noaa.gov/data/indices/oni.ascii.txt\\nPNA data URL: https://www.cpc.ncep.noaa.gov/products/precip/CWlink/pna/norm.pna.monthly.b5001.current.ascii\\nNAO data URL: https://www.cpc.ncep.noaa.gov/products/precip/CWlink/pna/norm.nao.monthly.b5001.current.ascii\\nAll teleconnections in one! ftp://ftp.cpc.ncep.noaa.gov/wd52dg/data/indices/tele_index.nh\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Author: Faron Anslow\n",
    "E-mail: faron.anslow@gmail.com\n",
    "\n",
    "This code generates a Dash web browser application that plots single station water-year snow evolution with\n",
    "controls to filter by station location and ENSO state. Default is to display the median and 1-sigma range\n",
    "for the entire record, the median and 1-sigma range for a selected ENSO condition and the current year's\n",
    "snowpack evolution.\n",
    "\n",
    "Future iterations will include a map-view component that will display the station locations with symbology\n",
    "that illustrates the relationship between various snow statistics (such as timing of peak, amplitude of peak,\n",
    "timing of peak melt, amplitude of peak melt and timing of snow loss) and seasonal teleconnection/variability\n",
    "patterns.\n",
    "\n",
    "Sources for snow data and teleconnection index values.\n",
    "Snow data URL: https://www.env.gov.bc.ca/wsd/data_searches/snow/asws/data/\n",
    "ONI data URL: https://www.cpc.ncep.noaa.gov/data/indices/oni.ascii.txt\n",
    "PNA data URL: https://www.cpc.ncep.noaa.gov/products/precip/CWlink/pna/norm.pna.monthly.b5001.current.ascii\n",
    "NAO data URL: https://www.cpc.ncep.noaa.gov/products/precip/CWlink/pna/norm.nao.monthly.b5001.current.ascii\n",
    "All teleconnections in one! ftp://ftp.cpc.ncep.noaa.gov/wd52dg/data/indices/tele_index.nh\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea350d06-f14c-4c98-9cfd-c02aca1be741",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 30)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc4062d1-50d5-4d11-86cb-4e161b8029e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, stations_with_current_year = load_munge_snow_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eb1a15c-8899-4cbb-9bbc-0c448d3bcaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#lets figure out how to make quantiles for each station/day and \n",
    "#compute the percentile amount relative to median for all stations.\n",
    "#The quantiles will need to be passed into the plotting function\n",
    "#To be shown.\n",
    "\n",
    "#We only need the median outside of the line plotting function, \n",
    "#so we can save the full quantile calculation for there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee9737f7-651f-497b-a660-3c3da10688e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Filter the location file by what's in the data file and vice versa so that there is 1:1\n",
    "#correspondence between the meta data file and the data file. Let's do this on the location ID\n",
    "#locdf\n",
    "datastnids = pd.Series([i.split(' ',1)[0] for i in df.columns.to_list()])\n",
    "datastnnames = pd.Series([i.split(' ',1)[1] for i in df.columns.to_list()])\n",
    "\n",
    "#Bring in the station meta data\n",
    "locdf = pd.read_csv('./snow/SNW_ASWS.csv')\n",
    "metastnids = locdf['LCTN_ID']\n",
    "datastnnames = datastnnames[datastnids.isin(metastnids)]\n",
    "datastnids = datastnids[datastnids.isin(metastnids)]\n",
    "metastnids = metastnids[metastnids.isin(datastnids)]\n",
    "\n",
    "#re-subset the dataframes so that the stations match one for one\n",
    "df = df.loc[:,(datastnids+' '+datastnnames)]\n",
    "locdf = locdf.loc[locdf['LCTN_ID'].isin(metastnids),:]\n",
    "#if ~(stations_with_current_year.isin(datastnids+' '+datastnnames).all()):\n",
    "#    raise\n",
    "\n",
    "locdf['text'] = locdf['LCTN_ID'] + ' ' + locdf['LCTN_NM'] + '<br>Elevation: ' + (locdf['ELEVATION']).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abef7953-7b20-47e6-ba03-08ea73eeb4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a column formatted that gives the hydrological year. Essentially the time index, forward by 3 months,\n",
    "# then reformatted to %Y using strftime.\n",
    "def datetimepandas(timestamp,theformat):\n",
    "    return datetime.strftime(timestamp,theformat)\n",
    "def hydrodoy_from_timestamp(timestamps):\n",
    "    \"\"\"\n",
    "    This function takes a pandas data Series object of timestamps and converts it into the day of the hydrological\n",
    "    year which starts on 1 October and runs through the end of September. Returns a pandas Series of those days of year.\n",
    "\n",
    "    Leap years are accommodated in an ugly way through making masks on the vector. I'm sure there are more elegant ways\n",
    "    of doing this!\n",
    "    \"\"\"\n",
    "    #Calculating the julian day is the first, necessary step.\n",
    "    hydrodoy = timestamps.apply(datetimepandas,args=('%j',)).astype(int)\n",
    "    #Next, need to link logic to operate one way for years where YEAR % 4 == 0 and anotherway for years where YEAR % 4 ~= 0\n",
    "    leapmask = timestamps.apply(datetime.strftime,args=('%Y',)).astype(int) % 4 == 0\n",
    "    hydrodoy = hydrodoy - 273\n",
    "    hydrodoy.loc[leapmask] = hydrodoy.loc[leapmask] - 1 #Adjust for the leap year\n",
    "    negleapmask = leapmask & (hydrodoy < 1)\n",
    "    hydrodoy = hydrodoy.mask(hydrodoy < 1, hydrodoy+365) #Correct the days of the year prior to 1 October back to their order\n",
    "    hydrodoy.loc[negleapmask] = hydrodoy.loc[negleapmask] + 1 #Adjust for the leap year\n",
    "    return hydrodoy\n",
    "\n",
    "def wateryear_from_timestamps(timestamps):\n",
    "    \"\"\"\n",
    "    This function takes a pandas data Series object of timestamps and determines the hydrological year the date\n",
    "    belongs to. Essentially, has to look at the year 92 days in the future.\n",
    "\n",
    "    Needs error trapping or at least some type checking.\n",
    "    \"\"\"\n",
    "    wateryears = timestamps + pd.Timedelta(\"92 day\")\n",
    "    wateryears = wateryears.apply(datetimepandas,args=('%Y',))\n",
    "    wateryears = wateryears.astype(int)\n",
    "    return wateryears\n",
    "\n",
    "# ## Station Snow Statistics\n",
    "#\n",
    "# Interested in being able to correlate ENSO with timing of peak snow and amount of snow at the peak. Also interested in magnitude of peak melt rate and timing of the peak melt rate. These satistics will be part of a map-based view of the station data that will be colourized by the level of correlation or by the percent of peak snow associated with the\n",
    "df['hydrodoy'] = hydrodoy_from_timestamp(df.index.to_series())\n",
    "df['hydrological_year'] = wateryear_from_timestamps(df.index.to_series())\n",
    "\n",
    "#Add on the month-day column for better plotting\n",
    "df['month-day'] = df.index.strftime('%m-%d')\n",
    "#Drop all leap years\n",
    "df = df.loc[(~(df['month-day']=='02-29')),:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63e074e5-b5d7-4358-ad23-e4d89f7ff7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', 150)\n",
    "#Find the number of years with more than 80% data coverage.\n",
    "nyears_complete = (df.groupby(by=\"hydrological_year\").apply(count_coverage,include_groups=False)*100/365 > 80).sum(axis='rows')\n",
    "nyears_complete = nyears_complete[:-2]\n",
    "#Get the peak snow each year:\n",
    "peak_annual_snow = df.iloc[:,:-1].groupby(by=\"hydrological_year\").max()\n",
    "peak_annual_snow = peak_annual_snow.iloc[:,:-1]\n",
    "historical_median_snow = df.iloc[:,:-2].groupby(by=\"hydrodoy\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af99c4dc-fdfb-4993-a0db-e879d34f19e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#peak_annual_snow\n",
    "dftest = df.copy()\n",
    "#keep the index\n",
    "dates = df.index\n",
    "dftest = dftest.set_index(['hydrodoy'],append=True).iloc[:,:-2]\n",
    "historical_median_snow = dftest.rolling(window=5,center=True).mean().groupby(level=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7c327f6-a36c-4acb-91d7-2011c01eb450",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dftest = dftest.iloc[:,:-3]\n",
    "dftest.sort_index(level=['hydrodoy'])\n",
    "#pd.set_option('display.max_rows', None)\n",
    "#dftest.loc[(slice(None),1),:]\n",
    "pd.set_option('display.max_rows', 30)\n",
    "snow_pct_median = 100*(dftest/historical_median_snow)\n",
    "snow_pct_median.replace([np.inf], 399, inplace=True)\n",
    "snow_pct_median[snow_pct_median > 399] = 400\n",
    "snow_pct_now = snow_pct_median.iloc[-1:,].reset_index(drop=True).T #=range(126) #= snow_pct_median.iloc[-1:,].T\n",
    "\n",
    "\n",
    "#check to see if we have a 1:1 match of the current snow percentage with the locations dataframe\n",
    "if (snow_pct_now.index == locdf['LCTN_ID'] + ' ' + locdf['LCTN_NM']).all():\n",
    "    locdf['pct_snow'] = snow_pct_now.iloc[:,0].values\n",
    "else:\n",
    "    None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4811d7b8-c54e-407e-8e05-50add94624cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnxonidata = get_wyear_extrema_oni()\n",
    "startrange = get_oni_startrange(mnxonidata)\n",
    "\n",
    "\n",
    "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "currentyear = df[['hydrological_year']].max()\n",
    "fillninoarea = 'rgba(255,110,95,0.3)'\n",
    "fillninoline = 'rgb(255,110,95)'\n",
    "fillninaarea = 'rgba(0,175,245,0.3)'\n",
    "fillninaline = 'rgb(0,175,245)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06e36a76-a5dc-45ce-82bb-bf2f0144fd41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8051/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f58af5e94d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "snowapp = Dash(__name__,\n",
    "                  external_stylesheets = [dbc.themes.SANDSTONE],\n",
    "                  title = 'ENSO Snow BC: exploring snow accumulation and El Nino/La Nina in British Columbia'\n",
    "              )\n",
    "server = snowapp.server\n",
    "snowapp.layout = html.Div([\n",
    "    #Call the function to produce the documentation using dcc.markdown\n",
    "    header_text_md(dcc),\n",
    "    dcc.Tabs(\n",
    "        children=[\n",
    "            dcc.Tab(\n",
    "                label='ENSO Snow BC',\n",
    "                children=[\n",
    "                    html.Div(className='row', children=[\n",
    "                        html.Div([\n",
    "                        #Want to implement a checklist here that allows for the selection of one or more of three\n",
    "                        #things\n",
    "                        #\n",
    "                        #1) Want to allow restriction to long records only\n",
    "                        #2) Want to allow restriction to records with current year only\n",
    "                        #3) Want an option to show only locations with data in an overlapping 30 years\n",
    "                        #   normal period or restricted normal period. 1991 -- 2020 or 2000\n",
    "                        #   to 2020 ideally and restrict the stats to those.\n",
    "                        dcc.Checklist(\n",
    "                            options=[\n",
    "                                {'label': 'Require current year?', 'value': 'rcy'},\n",
    "                                {'label': 'Require 20 or more years?', 'value': 'rtmy'},\n",
    "                            #    {'label': 'Require current normal preiod', 'value': 'rcnp'},\n",
    "                            ],\n",
    "                            value=['rcy'],\n",
    "                            #inline=True,\n",
    "                            id='record-length-current-check',\n",
    "                        )\n",
    "                    ], className='four columns',),\n",
    "                    html.Div([\n",
    "                    html.P(\"Filter by La Niña/El Niño Strength:\"),\n",
    "                    dcc.RangeSlider(\n",
    "                        min=-3,\n",
    "                        max=3,\n",
    "                        step=0.1,\n",
    "                        #Range slider with custom marks.\n",
    "                        marks={\n",
    "                            -2.7: {'label': 'Extreme La Niña', 'style': {'color': fillninaline}},\n",
    "                            -1.3: {'label': 'Mod. La Niña', 'style': {'color': fillninaline}},\n",
    "                            -0.50: {'label': 'Neutral', 'style': {'color': 'rgb(80,80,80)'}},\n",
    "                            0.50: {'label': 'Neutral', 'style': {'color': 'rgb(80,80,80)'}},\n",
    "                            1.3: {'label': 'Mod. El Niño', 'style': {'color': fillninoline}},\n",
    "                            2.7: {'label': 'Extreme El Niño', 'style': {'color': fillninoline}}\n",
    "                        },\n",
    "                        value=[startrange[0], startrange[1]],\n",
    "                        updatemode='drag',\n",
    "                        id='oni-range-slider'),\n",
    "                    ], className='eight columns',),\n",
    "                ]),\n",
    "                html.Div(className='row', children=[\n",
    "                    html.Div([\n",
    "                        dcc.Graph(\n",
    "                            id=\"snow-station-map\",\n",
    "                            #This is the initil point to draw data for. Clunky way of assigning it...\n",
    "                            clickData={'points': [{'text': '3A25P Squamish River Upper<br>Elevation: 1360.0'}]},\n",
    "                            #Get rid of the selection buttons in the map because they will confuse with\n",
    "                            #The select on click action that's desired.\n",
    "                            config={\n",
    "                                'modeBarButtonsToRemove': ['pan2d', 'lasso2d', 'select2d']\n",
    "                            }\n",
    "                        ),\n",
    "                    ], className='four columns',),\n",
    "                    html.Div([\n",
    "                        dcc.Graph(id=\"snow-station-graph\",\n",
    "                            config={\n",
    "                                'modeBarButtonsToRemove': ['zoom2d', 'pan2d', 'autoScale2d'],\n",
    "                                'modeBarButtonsToAdd': ['v1hovermode'],\n",
    "                            }\n",
    "                        ),\n",
    "                    ], className='eight columns'),\n",
    "                ]),\n",
    "                ]\n",
    "            ),\n",
    "            dcc.Tab(\n",
    "                label='Analysis',\n",
    "                children=[\n",
    "                    analysis_desc_md(dcc),\n",
    "                ]\n",
    "            ),\n",
    "            dcc.Tab(\n",
    "                label='Help',\n",
    "                children=[\n",
    "                    how_to_md(dcc),\n",
    "                ]\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    footer_text_md(dcc),\n",
    "])\n",
    "\n",
    "@snowapp.callback(\n",
    "    Output('snow-station-map', 'figure'),\n",
    "    Input('record-length-current-check','value'),\n",
    ")\n",
    "def make_station_map(reccheck):\n",
    "    '''\n",
    "    Work with the record length checklist to filter the location data according to\n",
    "    what is available in the master dataframe. The argument reccheck is the list\n",
    "    of strings created as output by the checklist that indicates the logical\n",
    "    filters. If present, then true, if absent, no filter.\n",
    "    '''\n",
    "    locdfuse = locdf\n",
    "    if ('rcy' in reccheck):\n",
    "        #Only keep stations with current year's data\n",
    "        locdfuse = locdfuse.loc[(locdfuse['LCTN_ID'] + ' ' + locdfuse['LCTN_NM']).isin(pd.Series(stations_with_current_year)),:]\n",
    "    if ('rtmy' in reccheck):\n",
    "        #Only keep stations that have 30 or more years of complete records.\n",
    "        locdfuse = locdfuse.loc[(locdfuse['LCTN_ID'] + ' ' + locdfuse['LCTN_NM']).isin(pd.Series(nyears_complete.index[nyears_complete >= 20])),:]\n",
    "\n",
    "    return draw_station_map(go,locdfuse)\n",
    "\n",
    "#Now make a callback that uses the values from the drop down and the slider selection to stratify the\n",
    "#data and make the plot\n",
    "\n",
    "@snowapp.callback(\n",
    "    Output('snow-station-graph', 'figure'),\n",
    "    Input('oni-range-slider', 'value'),\n",
    "    Input('snow-station-map', 'clickData'),\n",
    ")\n",
    "def update_line_chart(onirange,clickData):\n",
    "    '''\n",
    "    Function to take the output from the slider and the station map callbacks\n",
    "    and filter the master dataframe and the years according to the ONI magnitude\n",
    "    Then calls a subfunction to create the actual map.\n",
    "    '''\n",
    "    #Here's what the clickData look like:\n",
    "    #{'points': [{\n",
    "    #   'curveNumber': 0,\n",
    "    #   'pointNumber': 123,\n",
    "    #   'pointIndex': 123,\n",
    "    #   'lon': -128.711028,\n",
    "    #   'lat': 55.152028,\n",
    "    #   'text': '4B18P Cedar-Kiteen<br>Elevation: 885.0',\n",
    "    #   'bbox': {\n",
    "    #        'x0': 76.35033446674115,\n",
    "    #        'x1': 78.35033446674115,\n",
    "    #        'y0': 1802.8100327553746,\n",
    "    #        'y1': 1804.8100327553746\n",
    "    #   }\n",
    "    #}\n",
    "    #]\n",
    "    #}\n",
    "    #\n",
    "    stnname = clickData['points'][0]['text'].split('<br>')[0]\n",
    "    subdf = pd.pivot_table(\n",
    "                df[[stnname,'hydrological_year','month-day']],\n",
    "                index=['month-day'],\n",
    "                columns=\"hydrological_year\",\n",
    "                values=stnname\n",
    "            )\n",
    "    #The pivot re-orders the intex. \n",
    "    #need to stack the bottom onto the top to make a hydrological year\n",
    "    subdf = pd.concat([subdf.iloc[-92:,:],subdf.iloc[0:(366-92):,]],axis=0)\n",
    "    yearsuse = mnxonidata.index[(mnxonidata[\"ANOM\"] > onirange[0]) &\n",
    "        (mnxonidata[\"ANOM\"] < onirange[1])].unique()\n",
    "    if ((onirange[0] + onirange[1])/2 > 0):\n",
    "        fillarea = fillninoarea\n",
    "        fillline = fillninoline\n",
    "    else:\n",
    "        fillarea = fillninaarea\n",
    "        fillline = fillninaline\n",
    "\n",
    "    plottitle=\"Hydrologic Year SWE for \\\"{}\\\"<br>Oceanic Niño Index Range {} to {}\".format(stnname,onirange[0],onirange[1])\n",
    "    return snow_lineplot(\n",
    "        go,\n",
    "        pd,\n",
    "        subdf,\n",
    "        yearsuse,\n",
    "        currentyear,\n",
    "        fillarea,\n",
    "        fillline,\n",
    "        plottitle=plottitle\n",
    "    )\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    snowapp.run(debug=True,port=8051)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a014827c-fb05-404b-bc50-1ce1f01e9080",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
